{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b39f03-ef56-4516-9658-b4d3eff9d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098ccfcc1c5c491caffc63ba519bc121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=5\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-6.7b\", device_map=\"cpu\", torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-6.7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f508c55b-716e-4a66-916b-56d88bcc17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import cpu_offload\n",
    "\n",
    "model = cpu_offload(model, execution_device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96aeb5b0-bc2f-4007-afa8-f3787acfbea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malinovskijvl/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cuda, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The capital of France is\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generated_ids = model.generate(input_ids.cuda(), max_new_tokens=3)\n",
    "\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b283403-5f5d-4ef9-9e1a-84048648b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 20 20:28:32 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 4000                On  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8               9W / 125W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4000               On  | 00000000:05:00.0 Off |                  Off |\n",
      "| 41%   37C    P8              14W / 140W |  14869MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A4000               On  | 00000000:06:00.0 Off |                  Off |\n",
      "| 57%   70C    P2              51W / 140W |  12635MiB / 16376MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 4000                On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8               7W / 125W |    131MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 4000                On  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              11W / 125W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 4000                On  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 30%   44C    P0              37W / 125W |    545MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 4000                On  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8               9W / 125W |      1MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2248882      C   /home/nagornoval/shad/.venv/bin/python    14862MiB |\n",
      "|    2   N/A  N/A   2239911      C   /home/nagornoval/shad/.venv/bin/python    12628MiB |\n",
      "|    3   N/A  N/A   2212674      C   /home/abrahamma/gpu-env/bin/python          128MiB |\n",
      "|    5   N/A  N/A   2262525      C   /home/malinovskijvl/venv/bin/python3        542MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
